{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6176b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "RUNNING MULTIMODAL ANALYSIS WITH CORRECTED PERMUTATION TESTING\n",
      "========================================================================================================================\n",
      "\n",
      "================================================================================\n",
      "RUNNING ANALYSIS 1/1 WITH SEED 9\n",
      "================================================================================\n",
      "Loading all modality data...\n",
      "Shape of concatenated data for 02: (358, 32, 32, 5)\n",
      "Labels shape for 02: (358,), First label: 0\n",
      "Shape of concatenated data for 40: (358, 32, 32, 5)\n",
      "Labels shape for 40: (358,), First label: 2\n",
      "Shape of concatenated data for 75: (358, 32, 32, 5)\n",
      "Labels shape for 75: (358,), First label: 1\n",
      "Shape of concatenated data for 47: (358, 32, 32, 5)\n",
      "Labels shape for 47: (358,), First label: 1\n",
      "Shape of concatenated data for 32: (358, 32, 32, 5)\n",
      "Labels shape for 32: (358,), First label: 2\n",
      "Shape of concatenated data for 38: (358, 32, 32, 5)\n",
      "Labels shape for 38: (358,), First label: 1\n",
      "Shape of concatenated data for 25: (358, 32, 32, 5)\n",
      "Labels shape for 25: (358,), First label: 0\n",
      "Shape of concatenated data for 53: (358, 32, 32, 5)\n",
      "Labels shape for 53: (358,), First label: 1\n",
      "Shape of concatenated data for 64: (358, 32, 32, 5)\n",
      "Labels shape for 64: (358,), First label: 1\n",
      "Shape of concatenated data for 66: (358, 32, 32, 5)\n",
      "Labels shape for 66: (358,), First label: 1\n",
      "Shape of concatenated data for 20: (358, 32, 32, 5)\n",
      "Labels shape for 20: (358,), First label: 0\n",
      "Shape of concatenated data for 62: (358, 32, 32, 5)\n",
      "Labels shape for 62: (358,), First label: 1\n",
      "Shape of concatenated data for 18: (358, 32, 32, 5)\n",
      "Labels shape for 18: (358,), First label: 0\n",
      "Shape of concatenated data for 70: (358, 32, 32, 5)\n",
      "Labels shape for 70: (358,), First label: 1\n",
      "Shape of concatenated data for 31: (358, 32, 32, 5)\n",
      "Labels shape for 31: (358,), First label: 0\n",
      "Shape of concatenated data for 42: (358, 32, 32, 5)\n",
      "Labels shape for 42: (358,), First label: 2\n",
      "Shape of concatenated data for 57: (358, 32, 32, 5)\n",
      "Labels shape for 57: (358,), First label: 1\n",
      "Shape of concatenated data for 04: (358, 32, 32, 5)\n",
      "Labels shape for 04: (358,), First label: 0\n",
      "Shape of concatenated data for 07: (358, 32, 32, 5)\n",
      "Labels shape for 07: (358,), First label: 0\n",
      "Shape of concatenated data for 12: (358, 32, 32, 5)\n",
      "Labels shape for 12: (358,), First label: 0\n",
      "Shape of concatenated data for 24: (358, 32, 32, 5)\n",
      "Labels shape for 24: (358,), First label: 0\n",
      "Shape of concatenated data for 48: (358, 32, 32, 5)\n",
      "Labels shape for 48: (358,), First label: 2\n",
      "Shape of concatenated data for 23: (358, 32, 32, 5)\n",
      "Labels shape for 23: (358,), First label: 0\n",
      "Shape of concatenated data for 13: (358, 32, 32, 5)\n",
      "Labels shape for 13: (358,), First label: 0\n",
      "Shape of concatenated data for 73: (358, 32, 32, 5)\n",
      "Labels shape for 73: (358,), First label: 1\n",
      "Shape of concatenated data for 45: (358, 32, 32, 5)\n",
      "Labels shape for 45: (358,), First label: 2\n",
      "Shape of concatenated data for 11: (358, 32, 32, 5)\n",
      "Labels shape for 11: (358,), First label: 0\n",
      "Shape of concatenated data for 76: (358, 32, 32, 5)\n",
      "Labels shape for 76: (358,), First label: 1\n",
      "Shape of concatenated data for 26: (358, 32, 32, 5)\n",
      "Labels shape for 26: (358,), First label: 0\n",
      "Shape of concatenated data for 14: (358, 32, 32, 5)\n",
      "Labels shape for 14: (358,), First label: 0\n",
      "Shape of concatenated data for 33: (358, 32, 32, 5)\n",
      "Labels shape for 33: (358,), First label: 2\n",
      "Shape of concatenated data for 29: (358, 32, 32, 5)\n",
      "Labels shape for 29: (358,), First label: 0\n",
      "Shape of concatenated data for 16: (358, 32, 32, 5)\n",
      "Labels shape for 16: (358,), First label: 0\n",
      "Shape of concatenated data for 80: (358, 32, 32, 5)\n",
      "Labels shape for 80: (358,), First label: 1\n",
      "Shape of concatenated data for 08: (358, 32, 32, 5)\n",
      "Labels shape for 08: (358,), First label: 0\n",
      "Shape of concatenated data for 21: (358, 32, 32, 5)\n",
      "Labels shape for 21: (358,), First label: 0\n",
      "Shape of concatenated data for 01: (358, 32, 32, 5)\n",
      "Labels shape for 01: (358,), First label: 0\n",
      "Shape of concatenated data for 78: (358, 32, 32, 5)\n",
      "Labels shape for 78: (358,), First label: 1\n",
      "Shape of concatenated data for 74: (358, 32, 32, 5)\n",
      "Labels shape for 74: (358,), First label: 1\n",
      "Shape of concatenated data for 77: (358, 32, 32, 5)\n",
      "Labels shape for 77: (358,), First label: 1\n",
      "Shape of concatenated data for 65: (358, 32, 32, 5)\n",
      "Labels shape for 65: (358,), First label: 1\n",
      "Shape of concatenated data for 35: (358, 32, 32, 5)\n",
      "Labels shape for 35: (358,), First label: 2\n",
      "Shape of concatenated data for 79: (358, 32, 32, 5)\n",
      "Labels shape for 79: (358,), First label: 1\n",
      "Shape of concatenated data for 09: (358, 32, 32, 5)\n",
      "Labels shape for 09: (358,), First label: 0\n",
      "Shape of concatenated data for 41: (358, 32, 32, 5)\n",
      "Labels shape for 41: (358,), First label: 2\n",
      "Shape of concatenated data for 63: (358, 32, 32, 5)\n",
      "Labels shape for 63: (358,), First label: 1\n",
      "Shape of concatenated data for 17: (358, 32, 32, 5)\n",
      "Labels shape for 17: (358,), First label: 0\n",
      "Shape of concatenated data for 39: (358, 32, 32, 5)\n",
      "Labels shape for 39: (358,), First label: 2\n",
      "Shape of concatenated data for 37: (358, 32, 32, 5)\n",
      "Labels shape for 37: (358,), First label: 2\n",
      "Shape of concatenated data for 46: (358, 32, 32, 5)\n",
      "Labels shape for 46: (358,), First label: 2\n",
      "Shape of concatenated data for 10: (358, 32, 32, 5)\n",
      "Labels shape for 10: (358,), First label: 0\n",
      "Shape of concatenated data for 15: (358, 32, 32, 5)\n",
      "Labels shape for 15: (358,), First label: 0\n",
      "Shape of concatenated data for 68: (358, 32, 32, 5)\n",
      "Labels shape for 68: (358,), First label: 1\n",
      "Shape of concatenated data for 72: (358, 32, 32, 5)\n",
      "Labels shape for 72: (358,), First label: 1\n",
      "Shape of concatenated data for 43: (358, 32, 32, 5)\n",
      "Labels shape for 43: (358,), First label: 2\n",
      "Shape of concatenated data for 59: (358, 32, 32, 5)\n",
      "Labels shape for 59: (358,), First label: 1\n",
      "Shape of concatenated data for 05: (358, 32, 32, 5)\n",
      "Labels shape for 05: (358,), First label: 0\n",
      "Shape of concatenated data for 49: (358, 32, 32, 5)\n",
      "Labels shape for 49: (358,), First label: 2\n",
      "Shape of concatenated data for 36: (358, 32, 32, 5)\n",
      "Labels shape for 36: (358,), First label: 2\n",
      "Shape of concatenated data for 58: (358, 32, 32, 5)\n",
      "Labels shape for 58: (358,), First label: 1\n",
      "Shape of concatenated data for 03: (358, 32, 32, 5)\n",
      "Labels shape for 03: (358,), First label: 0\n",
      "Shape of concatenated data for 27: (358, 32, 32, 5)\n",
      "Labels shape for 27: (358,), First label: 0\n",
      "Shape of concatenated data for 67: (358, 32, 32, 5)\n",
      "Labels shape for 67: (358,), First label: 1\n",
      "Shape of concatenated data for 54: (358, 32, 32, 5)\n",
      "Labels shape for 54: (358,), First label: 2\n",
      "Shape of concatenated data for 56: (358, 32, 32, 5)\n",
      "Labels shape for 56: (358,), First label: 2\n",
      "Shape of concatenated data for 44: (358, 32, 32, 5)\n",
      "Labels shape for 44: (358,), First label: 2\n",
      "Subject 79: raw label = 1, numeric = 1\n",
      "Subject 32: raw label = 2, numeric = 2\n",
      "Subject 76: raw label = 1, numeric = 1\n",
      "Subject 54: raw label = 2, numeric = 2\n",
      "Subject 14: raw label = 0, numeric = 0\n",
      "Subject 59: raw label = 1, numeric = 1\n",
      "Subject 25: raw label = 0, numeric = 0\n",
      "Subject 29: raw label = 0, numeric = 0\n",
      "Subject 62: raw label = 1, numeric = 1\n",
      "Subject 38: raw label = 1, numeric = 1\n",
      "Subject 48: raw label = 2, numeric = 2\n",
      "Subject 03: raw label = 0, numeric = 0\n",
      "Subject 01: raw label = 0, numeric = 0\n",
      "Subject 10: raw label = 0, numeric = 0\n",
      "Subject 21: raw label = 0, numeric = 0\n",
      "Subject 56: raw label = 2, numeric = 2\n",
      "Subject 13: raw label = 0, numeric = 0\n",
      "Subject 64: raw label = 1, numeric = 1\n",
      "Subject 39: raw label = 2, numeric = 2\n",
      "Subject 58: raw label = 1, numeric = 1\n",
      "Subject 31: raw label = 0, numeric = 0\n",
      "Subject 44: raw label = 2, numeric = 2\n",
      "Subject 09: raw label = 0, numeric = 0\n",
      "Subject 07: raw label = 0, numeric = 0\n",
      "Subject 05: raw label = 0, numeric = 0\n",
      "Subject 35: raw label = 2, numeric = 2\n",
      "Subject 42: raw label = 2, numeric = 2\n",
      "Subject 75: raw label = 1, numeric = 1\n",
      "Subject 53: raw label = 1, numeric = 1\n",
      "Subject 80: raw label = 1, numeric = 1\n",
      "Subject 68: raw label = 1, numeric = 1\n",
      "Subject 20: raw label = 0, numeric = 0\n",
      "Subject 04: raw label = 0, numeric = 0\n",
      "Subject 47: raw label = 1, numeric = 1\n",
      "Subject 65: raw label = 1, numeric = 1\n",
      "Subject 16: raw label = 0, numeric = 0\n",
      "Subject 33: raw label = 2, numeric = 2\n",
      "Subject 73: raw label = 1, numeric = 1\n",
      "Subject 67: raw label = 1, numeric = 1\n",
      "Subject 70: raw label = 1, numeric = 1\n",
      "Subject 45: raw label = 2, numeric = 2\n",
      "Subject 78: raw label = 1, numeric = 1\n",
      "Subject 40: raw label = 2, numeric = 2\n",
      "Subject 24: raw label = 0, numeric = 0\n",
      "Subject 66: raw label = 1, numeric = 1\n",
      "Subject 23: raw label = 0, numeric = 0\n",
      "Subject 41: raw label = 2, numeric = 2\n",
      "Subject 08: raw label = 0, numeric = 0\n",
      "Subject 43: raw label = 2, numeric = 2\n",
      "Subject 26: raw label = 0, numeric = 0\n",
      "Subject 74: raw label = 1, numeric = 1\n",
      "Subject 15: raw label = 0, numeric = 0\n",
      "Subject 49: raw label = 2, numeric = 2\n",
      "Subject 17: raw label = 0, numeric = 0\n",
      "Subject 57: raw label = 1, numeric = 1\n",
      "Subject 02: raw label = 0, numeric = 0\n",
      "Subject 37: raw label = 2, numeric = 2\n",
      "Subject 12: raw label = 0, numeric = 0\n",
      "Subject 27: raw label = 0, numeric = 0\n",
      "Subject 18: raw label = 0, numeric = 0\n",
      "Subject 63: raw label = 1, numeric = 1\n",
      "Subject 72: raw label = 1, numeric = 1\n",
      "Subject 36: raw label = 2, numeric = 2\n",
      "Subject 77: raw label = 1, numeric = 1\n",
      "fMRI Label statistics: {1: 23, 2: 16, 0: 25}\n",
      "Loaded fMRI data for 64 subjects.\n",
      "Loaded sMRI data for 68 subjects.\n",
      "Loading psychometric data from: filtered_participants.tsv\n",
      "Available psychometric columns (75): ['age', 'sex', 'education', 'BMI', 'BDI', 'SES', 'RPM', 'EHI', 'NEO_NEU', 'NEO_EXT', 'NEO_OPE', 'NEO_AGR', 'NEO_CON', 'AUDIT', 'MINI-COPE_1', 'MINI-COPE_2', 'MINI-COPE_3', 'MINI-COPE_4', 'MINI-COPE_5', 'MINI-COPE_6', 'MINI-COPE_7', 'MINI-COPE_8', 'MINI-COPE_9', 'MINI-COPE_10', 'MINI-COPE_11', 'MINI-COPE_12', 'MINI-COPE_13', 'MINI-COPE_14', 'CVLT_1', 'CVLT_2', 'CVLT_3', 'CVLT_4', 'CVLT_5', 'CVLT_6', 'CVLT_7', 'CVLT_8', 'CVLT_9', 'CVLT_10', 'CVLT_11', 'CVLT_12', 'CVLT_13', 'leukocytes', 'erythrocytes', 'hemoglobin', 'hematocrit', 'MCV', 'MCH', 'MCHC', 'RDW-CV', 'platelets', 'PDW', 'MPV', 'P-LCR', 'neutrophils_%', 'lymphocytes_%', 'monocytes_%', 'eosinophils_%', 'basophils_%', 'total_cholesterol', 'cholesterol_HDL', 'non-HDL_cholesterol', 'LDL_cholesterol', 'triglycerides', 'HSV_r', 'learning_deficits', 'allergies', 'drugs', 'ibuprofen_intake', 'thyroid_diseases', 'hypertension', 'diabetes', 'other_diseases', 'smoking_status', 'coffee_status', 'dementia_history_parents']\n",
      "Found groups: ['N' 'A+P+' 'A+P-']\n",
      "\n",
      "=== Psychometric Data Loading Summary ===\n",
      "Total subjects processed: 77\n",
      "Subjects skipped: 0\n",
      "Features per subject: 75\n",
      "Class distribution:\n",
      "  N (label=0): 31 subjects\n",
      "  A+P+ (label=1): 20 subjects\n",
      "  A+P- (label=1): 26 subjects\n",
      "\n",
      "Original data loaded:\n",
      "EEG: 66 subjects\n",
      "fMRI: 64 subjects\n",
      "sMRI: 68 subjects\n",
      "Psychometric: 77 subjects\n",
      "=== Subject Filtering Analysis ===\n",
      "Modality_1: 66 subjects - ['01', '02', '03', '04', '05', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '20', '21', '23', '24', '25', '26', '27', '29', '31', '32', '33', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '53', '54', '56', '57', '58', '59', '62', '63', '64', '65', '66', '67', '68', '70', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "Modality_2: 64 subjects - ['01', '02', '03', '04', '05', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '20', '21', '23', '24', '25', '26', '27', '29', '31', '32', '33', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '47', '48', '49', '53', '54', '56', '57', '58', '59', '62', '63', '64', '65', '66', '67', '68', '70', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "Modality_3: 68 subjects - ['01', '02', '03', '04', '05', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '23', '24', '25', '26', '27', '29', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '53', '54', '55', '56', '57', '58', '59', '62', '63', '64', '65', '66', '67', '68', '70', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "Modality_4: 77 subjects - ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '47', '48', '49', '50', '51', '52', '53', '54', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "\n",
      "Common subjects across all modalities: 64\n",
      "Common subject IDs: ['01', '02', '03', '04', '05', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '20', '21', '23', '24', '25', '26', '27', '29', '31', '32', '33', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '47', '48', '49', '53', '54', '56', '57', '58', '59', '62', '63', '64', '65', '66', '67', '68', '70', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "Modality_1 extra: ['11', '46']\n",
      "Modality_3 extra: ['19', '34', '46', '55']\n",
      "Modality_4 extra: ['06', '11', '19', '22', '28', '30', '34', '50', '51', '52', '60', '61', '71']\n",
      "\n",
      "=== Filtering Results ===\n",
      "Modality_1: 64 subjects retained\n",
      "Modality_2: 64 subjects retained\n",
      "Modality_3: 64 subjects retained\n",
      "Modality_4: 64 subjects retained\n",
      "\n",
      "=== Final Filtered Results ===\n",
      "Subjects with ALL four modalities: 64\n",
      "Subject IDs: ['01', '02', '03', '04', '05', '07', '08', '09', '10', '12', '13', '14', '15', '16', '17', '18', '20', '21', '23', '24', '25', '26', '27', '29', '31', '32', '33', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '47', '48', '49', '53', '54', '56', '57', '58', '59', '62', '63', '64', '65', '66', '67', '68', '70', '72', '73', '74', '75', '76', '77', '78', '79', '80']\n",
      "Verification - EEG: 64, fMRI: 64, sMRI: 64, Psychometric: 64\n",
      "\n",
      "Extracting features for classes: ('A+P-', 'A+P+')\n",
      "Total common subjects: 64\n",
      "dict_keys(['64', '64_label', '80', '80_label', '16', '16_label', '31', '31_label', '13', '13_label', '02', '02_label', '29', '29_label', '21', '21_label', '68', '68_label', '59', '59_label', '75', '75_label', '62', '62_label', '56', '56_label', '47', '47_label', '49', '49_label', '66', '66_label', '08', '08_label', '44', '44_label', '07', '07_label', '73', '73_label', '63', '63_label', '72', '72_label', '01', '01_label', '53', '53_label', '78', '78_label', '54', '54_label', '35', '35_label', '03', '03_label', '04', '04_label', '24', '24_label', '76', '76_label', '41', '41_label', '39', '39_label', '09', '09_label', '67', '67_label', '23', '23_label', '74', '74_label', '17', '17_label', '05', '05_label', '15', '15_label', '18', '18_label', '12', '12_label', '70', '70_label', '27', '27_label', '25', '25_label', '20', '20_label', '37', '37_label', '32', '32_label', '10', '10_label', '40', '40_label', '77', '77_label', '14', '14_label', '26', '26_label', '43', '43_label', '45', '45_label', '58', '58_label', '79', '79_label', '42', '42_label', '57', '57_label', '38', '38_label', '33', '33_label', '48', '48_label', '36', '36_label', '65', '65_label'])\n",
      "dict_keys(['64', '64_label', '80', '80_label', '16', '16_label', '31', '31_label', '13', '13_label', '02', '02_label', '29', '29_label', '21', '21_label', '68', '68_label', '59', '59_label', '75', '75_label', '62', '62_label', '56', '56_label', '47', '47_label', '49', '49_label', '66', '66_label', '08', '08_label', '44', '44_label', '07', '07_label', '73', '73_label', '63', '63_label', '72', '72_label', '01', '01_label', '53', '53_label', '78', '78_label', '54', '54_label', '35', '35_label', '03', '03_label', '04', '04_label', '24', '24_label', '76', '76_label', '41', '41_label', '39', '39_label', '09', '09_label', '67', '67_label', '23', '23_label', '74', '74_label', '17', '17_label', '05', '05_label', '15', '15_label', '18', '18_label', '12', '12_label', '70', '70_label', '27', '27_label', '25', '25_label', '20', '20_label', '37', '37_label', '32', '32_label', '10', '10_label', '40', '40_label', '77', '77_label', '14', '14_label', '26', '26_label', '43', '43_label', '45', '45_label', '58', '58_label', '79', '79_label', '42', '42_label', '57', '57_label', '38', '38_label', '33', '33_label', '48', '48_label', '36', '36_label', '65', '65_label'])\n",
      "dict_keys(['64', '80', '16', '31', '13', '02', '29', '21', '68', '59', '75', '62', '56', '47', '49', '66', '08', '44', '07', '73', '63', '72', '01', '53', '78', '54', '35', '03', '04', '24', '76', '41', '39', '09', '67', '23', '74', '17', '05', '15', '18', '12', '70', '27', '25', '20', '37', '32', '10', '40', '77', '14', '26', '43', '45', '58', '79', '42', '57', '38', '33', '48', '36', '65'])\n",
      "dict_keys(['64', '80', '16', '31', '13', '02', '29', '21', '68', '59', '75', '62', '56', '47', '49', '66', '08', '44', '07', '73', '63', '72', '01', '53', '78', '54', '35', '03', '04', '24', '76', '41', '39', '09', '67', '23', '74', '17', '05', '15', '18', '12', '70', '27', '25', '20', '37', '32', '10', '40', '77', '14', '26', '43', '45', '58', '79', '42', '57', '38', '33', '48', '36', '65'])\n",
      "DEBUG - eeg: Subjects checked: 64, with target classes: 39\n",
      "eeg - Classes: ('A+P-', 'A+P+'), Subjects: 39, Samples: 13962\n",
      "eeg - Label distribution after mapping: [8234 5728]\n",
      "DEBUG - fMRI: Checking label values for first few subjects...\n",
      "  Subject 64: labels = [1] (shape: (218,))\n",
      "  Subject 80: labels = [1] (shape: (218,))\n",
      "  Subject 16: labels = [0] (shape: (218,))\n",
      "  Subject 31: labels = [0] (shape: (218,))\n",
      "  Subject 13: labels = [0] (shape: (218,))\n",
      "All available labels in fMRI: [np.int64(0), np.int64(1), np.int64(2)]\n",
      "Looking for classes_int: [1, 2]\n",
      "  Subject 16: first_label = 0, not in [1, 2]\n",
      "  Subject 31: first_label = 0, not in [1, 2]\n",
      "  Subject 13: first_label = 0, not in [1, 2]\n",
      "DEBUG - fMRI: Subjects checked: 64, with target classes: 39\n",
      "fMRI - Classes: ('A+P-', 'A+P+'), Subjects: 39, Samples: 8502\n",
      "fMRI - Label distribution after mapping: [5014 3488]\n",
      "DEBUG - sMRI: Subjects checked: 64, with target classes: 39\n",
      "sMRI - Classes: ('A+P-', 'A+P+'), Subjects: 39, Samples: 39\n",
      "sMRI - Label distribution after mapping: [23 16]\n",
      "Psychometric label mapping: {'A+P-': 0, 'A+P+': 1}\n",
      "Psychometric - Classes: ('A+P-', 'A+P+'), Label mapping: {'A+P-': 0, 'A+P+': 1}\n",
      "Loaded 39 subjects\n",
      "Feature shape: (39, 75)\n",
      "Labels: [0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 1\n",
      " 1 0]\n",
      "Unique labels: [0 1]\n",
      "Subjects: 39, Samples: 39\n",
      "\n",
      "=== Final Feature Extraction Results ===\n",
      "Classes selected: ('A+P-', 'A+P+')\n",
      "EEG: (13962, 32, 32, 5) features, 39 subjects, 13962 samples\n",
      "fMRI: (8502, 4950) features, 39 subjects, 8502 samples\n",
      "sMRI: (39, 1610) features, 39 subjects, 39 samples\n",
      "Psychometric: (39, 75) features, 39 subjects, 39 samples\n",
      "Processing fold 1/39\n",
      "Running sMRI permutations for fold 1...\n",
      "Running Psychometric permutations for fold 1...\n",
      "Training fMRI K-means models for fold 1...\n",
      "Running fMRI permutations for fold 1...\n",
      "Training EEG K-means models for fold 1...\n",
      "Running EEG permutations for fold 1...\n",
      "Processing fold 2/39\n",
      "Running sMRI permutations for fold 2...\n",
      "Running Psychometric permutations for fold 2...\n",
      "Training fMRI K-means models for fold 2...\n",
      "Running fMRI permutations for fold 2...\n",
      "Training EEG K-means models for fold 2...\n",
      "Running EEG permutations for fold 2...\n",
      "Processing fold 3/39\n",
      "Running sMRI permutations for fold 3...\n",
      "Running Psychometric permutations for fold 3...\n",
      "Training fMRI K-means models for fold 3...\n",
      "Running fMRI permutations for fold 3...\n",
      "Training EEG K-means models for fold 3...\n",
      "Running EEG permutations for fold 3...\n",
      "Processing fold 4/39\n",
      "Running sMRI permutations for fold 4...\n",
      "Running Psychometric permutations for fold 4...\n",
      "Training fMRI K-means models for fold 4...\n",
      "Running fMRI permutations for fold 4...\n",
      "Training EEG K-means models for fold 4...\n",
      "Running EEG permutations for fold 4...\n",
      "Processing fold 5/39\n",
      "Running sMRI permutations for fold 5...\n",
      "Running Psychometric permutations for fold 5...\n",
      "Training fMRI K-means models for fold 5...\n",
      "Running fMRI permutations for fold 5...\n",
      "Training EEG K-means models for fold 5...\n",
      "Running EEG permutations for fold 5...\n",
      "Processing fold 6/39\n",
      "Running sMRI permutations for fold 6...\n",
      "Running Psychometric permutations for fold 6...\n",
      "Training fMRI K-means models for fold 6...\n",
      "Running fMRI permutations for fold 6...\n",
      "Training EEG K-means models for fold 6...\n",
      "Running EEG permutations for fold 6...\n",
      "Processing fold 7/39\n",
      "Running sMRI permutations for fold 7...\n",
      "Running Psychometric permutations for fold 7...\n",
      "Training fMRI K-means models for fold 7...\n",
      "Running fMRI permutations for fold 7...\n",
      "Training EEG K-means models for fold 7...\n",
      "Running EEG permutations for fold 7...\n",
      "Processing fold 8/39\n",
      "Running sMRI permutations for fold 8...\n",
      "Running Psychometric permutations for fold 8...\n",
      "Training fMRI K-means models for fold 8...\n",
      "Running fMRI permutations for fold 8...\n",
      "Training EEG K-means models for fold 8...\n",
      "Running EEG permutations for fold 8...\n",
      "Processing fold 9/39\n",
      "Running sMRI permutations for fold 9...\n",
      "Running Psychometric permutations for fold 9...\n",
      "Training fMRI K-means models for fold 9...\n",
      "Running fMRI permutations for fold 9...\n",
      "Training EEG K-means models for fold 9...\n",
      "Running EEG permutations for fold 9...\n",
      "Processing fold 10/39\n",
      "Running sMRI permutations for fold 10...\n",
      "Running Psychometric permutations for fold 10...\n",
      "Training fMRI K-means models for fold 10...\n",
      "Running fMRI permutations for fold 10...\n",
      "Training EEG K-means models for fold 10...\n",
      "Running EEG permutations for fold 10...\n",
      "Processing fold 11/39\n",
      "Running sMRI permutations for fold 11...\n",
      "Running Psychometric permutations for fold 11...\n",
      "Training fMRI K-means models for fold 11...\n",
      "Running fMRI permutations for fold 11...\n",
      "Training EEG K-means models for fold 11...\n",
      "Running EEG permutations for fold 11...\n",
      "Processing fold 12/39\n",
      "Running sMRI permutations for fold 12...\n",
      "Running Psychometric permutations for fold 12...\n",
      "Training fMRI K-means models for fold 12...\n",
      "Running fMRI permutations for fold 12...\n",
      "Training EEG K-means models for fold 12...\n",
      "Running EEG permutations for fold 12...\n",
      "Processing fold 13/39\n",
      "Running sMRI permutations for fold 13...\n",
      "Running Psychometric permutations for fold 13...\n",
      "Training fMRI K-means models for fold 13...\n",
      "Running fMRI permutations for fold 13...\n",
      "Training EEG K-means models for fold 13...\n",
      "Running EEG permutations for fold 13...\n",
      "Processing fold 14/39\n",
      "Running sMRI permutations for fold 14...\n",
      "Running Psychometric permutations for fold 14...\n",
      "Training fMRI K-means models for fold 14...\n",
      "Running fMRI permutations for fold 14...\n",
      "Training EEG K-means models for fold 14...\n",
      "Running EEG permutations for fold 14...\n",
      "Processing fold 15/39\n",
      "Running sMRI permutations for fold 15...\n",
      "Running Psychometric permutations for fold 15...\n",
      "Training fMRI K-means models for fold 15...\n",
      "Running fMRI permutations for fold 15...\n",
      "Training EEG K-means models for fold 15...\n",
      "Running EEG permutations for fold 15...\n",
      "Processing fold 16/39\n",
      "Running sMRI permutations for fold 16...\n",
      "Running Psychometric permutations for fold 16...\n",
      "Training fMRI K-means models for fold 16...\n",
      "Running fMRI permutations for fold 16...\n",
      "Training EEG K-means models for fold 16...\n",
      "Running EEG permutations for fold 16...\n",
      "Processing fold 17/39\n",
      "Running sMRI permutations for fold 17...\n",
      "Running Psychometric permutations for fold 17...\n",
      "Training fMRI K-means models for fold 17...\n",
      "Running fMRI permutations for fold 17...\n",
      "Training EEG K-means models for fold 17...\n",
      "Running EEG permutations for fold 17...\n",
      "Processing fold 18/39\n",
      "Running sMRI permutations for fold 18...\n",
      "Running Psychometric permutations for fold 18...\n",
      "Training fMRI K-means models for fold 18...\n",
      "Running fMRI permutations for fold 18...\n",
      "Training EEG K-means models for fold 18...\n",
      "Running EEG permutations for fold 18...\n",
      "Processing fold 19/39\n",
      "Running sMRI permutations for fold 19...\n",
      "Running Psychometric permutations for fold 19...\n",
      "Training fMRI K-means models for fold 19...\n",
      "Running fMRI permutations for fold 19...\n",
      "Training EEG K-means models for fold 19...\n",
      "Running EEG permutations for fold 19...\n",
      "Processing fold 20/39\n",
      "Running sMRI permutations for fold 20...\n",
      "Running Psychometric permutations for fold 20...\n",
      "Training fMRI K-means models for fold 20...\n",
      "Running fMRI permutations for fold 20...\n",
      "Training EEG K-means models for fold 20...\n",
      "Running EEG permutations for fold 20...\n",
      "Processing fold 21/39\n",
      "Running sMRI permutations for fold 21...\n",
      "Running Psychometric permutations for fold 21...\n",
      "Training fMRI K-means models for fold 21...\n",
      "Running fMRI permutations for fold 21...\n",
      "Training EEG K-means models for fold 21...\n",
      "Running EEG permutations for fold 21...\n",
      "Processing fold 22/39\n",
      "Running sMRI permutations for fold 22...\n",
      "Running Psychometric permutations for fold 22...\n",
      "Training fMRI K-means models for fold 22...\n",
      "Running fMRI permutations for fold 22...\n",
      "Training EEG K-means models for fold 22...\n",
      "Running EEG permutations for fold 22...\n",
      "Processing fold 23/39\n",
      "Running sMRI permutations for fold 23...\n",
      "Running Psychometric permutations for fold 23...\n",
      "Training fMRI K-means models for fold 23...\n",
      "Running fMRI permutations for fold 23...\n",
      "Training EEG K-means models for fold 23...\n",
      "Running EEG permutations for fold 23...\n",
      "Processing fold 24/39\n",
      "Running sMRI permutations for fold 24...\n",
      "Running Psychometric permutations for fold 24...\n",
      "Training fMRI K-means models for fold 24...\n",
      "Running fMRI permutations for fold 24...\n",
      "Training EEG K-means models for fold 24...\n",
      "Running EEG permutations for fold 24...\n",
      "Processing fold 25/39\n",
      "Running sMRI permutations for fold 25...\n",
      "Running Psychometric permutations for fold 25...\n",
      "Training fMRI K-means models for fold 25...\n",
      "Running fMRI permutations for fold 25...\n",
      "Training EEG K-means models for fold 25...\n",
      "Running EEG permutations for fold 25...\n",
      "Processing fold 26/39\n",
      "Running sMRI permutations for fold 26...\n",
      "Running Psychometric permutations for fold 26...\n",
      "Training fMRI K-means models for fold 26...\n",
      "Running fMRI permutations for fold 26...\n",
      "Training EEG K-means models for fold 26...\n",
      "Running EEG permutations for fold 26...\n",
      "Processing fold 27/39\n",
      "Running sMRI permutations for fold 27...\n",
      "Running Psychometric permutations for fold 27...\n",
      "Training fMRI K-means models for fold 27...\n",
      "Running fMRI permutations for fold 27...\n",
      "Training EEG K-means models for fold 27...\n",
      "Running EEG permutations for fold 27...\n",
      "Processing fold 28/39\n",
      "Running sMRI permutations for fold 28...\n",
      "Running Psychometric permutations for fold 28...\n",
      "Training fMRI K-means models for fold 28...\n",
      "Running fMRI permutations for fold 28...\n",
      "Training EEG K-means models for fold 28...\n",
      "Running EEG permutations for fold 28...\n",
      "Processing fold 29/39\n",
      "Running sMRI permutations for fold 29...\n",
      "Running Psychometric permutations for fold 29...\n",
      "Training fMRI K-means models for fold 29...\n",
      "Running fMRI permutations for fold 29...\n",
      "Training EEG K-means models for fold 29...\n",
      "Running EEG permutations for fold 29...\n",
      "Processing fold 30/39\n",
      "Running sMRI permutations for fold 30...\n",
      "Running Psychometric permutations for fold 30...\n",
      "Training fMRI K-means models for fold 30...\n",
      "Running fMRI permutations for fold 30...\n",
      "Training EEG K-means models for fold 30...\n",
      "Running EEG permutations for fold 30...\n",
      "Processing fold 31/39\n",
      "Running sMRI permutations for fold 31...\n",
      "Running Psychometric permutations for fold 31...\n",
      "Training fMRI K-means models for fold 31...\n",
      "Running fMRI permutations for fold 31...\n",
      "Training EEG K-means models for fold 31...\n",
      "Running EEG permutations for fold 31...\n",
      "Processing fold 32/39\n",
      "Running sMRI permutations for fold 32...\n",
      "Running Psychometric permutations for fold 32...\n",
      "Training fMRI K-means models for fold 32...\n",
      "Running fMRI permutations for fold 32...\n",
      "Training EEG K-means models for fold 32...\n",
      "Running EEG permutations for fold 32...\n",
      "Processing fold 33/39\n",
      "Running sMRI permutations for fold 33...\n",
      "Running Psychometric permutations for fold 33...\n",
      "Training fMRI K-means models for fold 33...\n",
      "Running fMRI permutations for fold 33...\n",
      "Training EEG K-means models for fold 33...\n",
      "Running EEG permutations for fold 33...\n",
      "Processing fold 34/39\n",
      "Running sMRI permutations for fold 34...\n",
      "Running Psychometric permutations for fold 34...\n",
      "Training fMRI K-means models for fold 34...\n",
      "Running fMRI permutations for fold 34...\n",
      "Training EEG K-means models for fold 34...\n",
      "Running EEG permutations for fold 34...\n",
      "Processing fold 35/39\n",
      "Running sMRI permutations for fold 35...\n",
      "Running Psychometric permutations for fold 35...\n",
      "Training fMRI K-means models for fold 35...\n",
      "Running fMRI permutations for fold 35...\n",
      "Training EEG K-means models for fold 35...\n",
      "Running EEG permutations for fold 35...\n",
      "Processing fold 36/39\n",
      "Running sMRI permutations for fold 36...\n",
      "Running Psychometric permutations for fold 36...\n",
      "Training fMRI K-means models for fold 36...\n",
      "Running fMRI permutations for fold 36...\n",
      "Training EEG K-means models for fold 36...\n",
      "Running EEG permutations for fold 36...\n",
      "Processing fold 37/39\n",
      "Running sMRI permutations for fold 37...\n",
      "Running Psychometric permutations for fold 37...\n",
      "Training fMRI K-means models for fold 37...\n",
      "Running fMRI permutations for fold 37...\n",
      "Training EEG K-means models for fold 37...\n",
      "Running EEG permutations for fold 37...\n",
      "Processing fold 38/39\n",
      "Running sMRI permutations for fold 38...\n",
      "Running Psychometric permutations for fold 38...\n",
      "Training fMRI K-means models for fold 38...\n",
      "Running fMRI permutations for fold 38...\n",
      "Training EEG K-means models for fold 38...\n",
      "Running EEG permutations for fold 38...\n",
      "Processing fold 39/39\n",
      "Running sMRI permutations for fold 39...\n",
      "Running Psychometric permutations for fold 39...\n",
      "Training fMRI K-means models for fold 39...\n",
      "Running fMRI permutations for fold 39...\n",
      "Training EEG K-means models for fold 39...\n",
      "Running EEG permutations for fold 39...\n",
      "\n",
      "ðŸŽ¯ OVERALL AUC SCORES ACROSS ALL FOLDS:\n",
      "   sMRI: 0.6522\n",
      "   Psychometric: 0.8804\n",
      "   fMRI: 0.6685\n",
      "   EEG: 0.2120\n",
      "Run 1 completed successfully!\n",
      "\n",
      "========================================================================================================================\n",
      "COMPUTING AGGREGATE STATISTICS ACROSS RUNS\n",
      "========================================================================================================================\n",
      "\n",
      "COMPLETE RESULTS TABLE - SORTED BY MEAN AUC ROC\n",
      "======================================================================================================================================================\n",
      "                     Combination Accuracy (Î¼) Accuracy (Ïƒ) F1 Score (Î¼) F1 Score (Ïƒ) Precision (Î¼) Precision (Ïƒ) Recall (Î¼) Recall (Ïƒ) AUC ROC (Î¼) AUC ROC (Ïƒ)\n",
      "                    Psychometric       0.7949          nan       0.7880          nan        0.7880           nan     0.7880        nan      0.8804         nan\n",
      "             Psychometric + fMRI       0.8205          nan       0.8162          nan        0.8142           nan     0.8193        nan      0.8804         nan\n",
      "       Psychometric + fMRI + EEG       0.7436          nan       0.7292          nan        0.7371           nan     0.7255        nan      0.8614         nan\n",
      "      sMRI + Psychometric + fMRI       0.7436          nan       0.7351          nan        0.7351           nan     0.7351        nan      0.8478         nan\n",
      "             sMRI + Psychometric       0.8205          nan       0.8126          nan        0.8167           nan     0.8098        nan      0.8424         nan\n",
      "              Psychometric + EEG       0.7692          nan       0.7591          nan        0.7625           nan     0.7568        nan      0.8288         nan\n",
      "sMRI + Psychometric + fMRI + EEG       0.7179          nan       0.7056          nan        0.7083           nan     0.7038        nan      0.8152         nan\n",
      "       sMRI + Psychometric + EEG       0.7436          nan       0.7214          nan        0.7454           nan     0.7160        nan      0.8016         nan\n",
      "                            fMRI       0.6410          nan       0.6389          nan        0.6434           nan     0.6481        nan      0.6685         nan\n",
      "                     sMRI + fMRI       0.6154          nan       0.6061          nan        0.6056           nan     0.6073        nan      0.6576         nan\n",
      "                            sMRI       0.5641          nan       0.5334          nan        0.5385           nan     0.5353        nan      0.6522         nan\n",
      "                      sMRI + EEG       0.5385          nan       0.5125          nan        0.5143           nan     0.5136        nan      0.6114         nan\n",
      "               Neuroimaging Only       0.5641          nan       0.5450          nan        0.5458           nan     0.5448        nan      0.6005         nan\n",
      "               sMRI + fMRI + EEG       0.5641          nan       0.5450          nan        0.5458           nan     0.5448        nan      0.6005         nan\n",
      "                      fMRI + EEG       0.4872          nan       0.4786          nan        0.4802           nan     0.4796        nan      0.5353         nan\n",
      "                             EEG       0.2564          nan       0.2564          nan        0.2649           nan     0.2649        nan      0.2120         nan\n",
      "\n",
      "========================================================================================================================\n",
      "CORRECTED PERMUTATION TEST RESULTS FOR SINGLE MODALITIES\n",
      "========================================================================================================================\n",
      "             Observed_Mean_AUC Permutation_p_value  Num_Permutations Significant_at_0.05 Permutation_Mean_AUC Permutation_Std_AUC\n",
      "sMRI                    0.6522              0.0420              1000                 Yes               0.4707              0.0935\n",
      "Psychometric            0.8804              0.0010              1000                 Yes               0.4695              0.0933\n",
      "fMRI                    0.6685              0.0410              1000                 Yes               0.4951              0.0909\n",
      "EEG                     0.2120              0.9990              1000                  No               0.4888              0.0971\n",
      "\n",
      "NOTE: AUC now computed OVERALL across all Leave-One-Out folds (not per-fold).\n",
      "This provides the correct statistical comparison for permutation testing.\n",
      "Significant results (p < 0.05) suggest the modality performs better than chance.\n",
      "\n",
      "\n",
      "RESULTS AND FEATURES SAVED IN: 'results_AplusPminus_vs_AplusPplus'\n",
      "- Individual runs: results_AplusPminus_vs_AplusPplus/multimodal_results_all_runs.csv\n",
      "- Aggregated mean/std: results_AplusPminus_vs_AplusPplus/multimodal_results_aggregated.csv\n",
      "- Permutation results: results_AplusPminus_vs_AplusPplus/permutation_test_results.csv\n",
      "- Permutation distributions: results_AplusPminus_vs_AplusPplus/permutation_distributions.npz\n",
      "- Top features saved in: results_AplusPminus_vs_AplusPplus/top_features\n",
      "\n",
      "========================================================================================================================\n",
      "TOP 5 PERFORMERS BY MEAN AUC ROC\n",
      "========================================================================================================================\n",
      "               combination auc_roc_mean auc_roc_std\n",
      "              Psychometric       0.8804         nan\n",
      "       Psychometric + fMRI       0.8804         nan\n",
      " Psychometric + fMRI + EEG       0.8614         nan\n",
      "sMRI + Psychometric + fMRI       0.8478         nan\n",
      "       sMRI + Psychometric       0.8424         nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def run_permutation_analysis(seed_val, classes, n_permutations=1000):\n",
    "    \"\"\"Run only permutation testing to generate null distributions.\"\"\"\n",
    "    \n",
    "    # Create a directory for the classification task results\n",
    "    class_str = \"_vs_\".join(classes).replace(\"+\", \"plus\").replace(\"-\", \"minus\")\n",
    "    output_dir = f\"results_{class_str}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    from utils import load_multimodal_data\n",
    "    \n",
    "    multimodal_data = load_multimodal_data(classes=classes, verbose=True)\n",
    "    \n",
    "    # Extract data for each modality\n",
    "    eeg_data = multimodal_data['eeg']\n",
    "    fmri_data = multimodal_data['fmri']\n",
    "    smri_data = multimodal_data['smri']\n",
    "    psychometric_data = multimodal_data['psychometric']\n",
    "    \n",
    "    # Sort all sub_ids in ascending order for all modalities\n",
    "    eeg_sort_indices = eeg_data['sub_ids'].argsort()\n",
    "    fmri_sort_indices = fmri_data['sub_ids'].argsort()\n",
    "    smri_sort_indices = smri_data['sub_ids'].argsort()\n",
    "    psychometric_sort_indices = psychometric_data['sub_ids'].argsort()\n",
    "    \n",
    "    eeg_data['sub_ids'] = eeg_data['sub_ids'][eeg_sort_indices]\n",
    "    eeg_data['X'] = eeg_data['X'][eeg_sort_indices]\n",
    "    eeg_data['y'] = eeg_data['y'][eeg_sort_indices]\n",
    "    fmri_data['sub_ids'] = fmri_data['sub_ids'][fmri_sort_indices]\n",
    "    fmri_data['X'] = fmri_data['X'][fmri_sort_indices]\n",
    "    fmri_data['y'] = fmri_data['y'][fmri_sort_indices]\n",
    "    smri_data['sub_ids'] = smri_data['sub_ids'][smri_sort_indices]\n",
    "    smri_data['X'] = smri_data['X'][smri_sort_indices]\n",
    "    smri_data['y'] = smri_data['y'][smri_sort_indices]\n",
    "    psychometric_data['sub_ids'] = psychometric_data['sub_ids'][psychometric_sort_indices]\n",
    "    psychometric_data['X'] = psychometric_data['X'][psychometric_sort_indices]\n",
    "    psychometric_data['y'] = psychometric_data['y'][psychometric_sort_indices]\n",
    "    \n",
    "    from sklearn.model_selection import LeaveOneOut\n",
    "    from sklearn.metrics import f1_score\n",
    "    import numpy as np\n",
    "    \n",
    "    # Since all modalities have the same subjects, we can use any modality to get subject info\n",
    "    unique_subjects = smri_data['sub_ids']\n",
    "    subject_labels = smri_data['y']\n",
    "    \n",
    "    loo = LeaveOneOut()\n",
    "    dummy_X = np.zeros((len(unique_subjects), 1))\n",
    "    \n",
    "    fold_splits = []\n",
    "    for fold, (train_subjects_idx, test_subjects_idx) in enumerate(loo.split(dummy_X, subject_labels)):\n",
    "        train_subjects = unique_subjects[train_subjects_idx]\n",
    "        test_subjects = unique_subjects[test_subjects_idx]\n",
    "        fold_splits.append((train_subjects, test_subjects))\n",
    "    \n",
    "    def get_indices_for_subjects(sub_ids, target_subjects):\n",
    "        return np.isin(sub_ids, target_subjects)\n",
    "    \n",
    "    import xgboost as xgb\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "    from sklearn.cluster import KMeans\n",
    "    \n",
    "    SEED = seed_val\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    \n",
    "    # Store permutation results across all folds for each permutation\n",
    "    permutation_predictions = {\n",
    "        'sMRI': [[] for _ in range(n_permutations)],\n",
    "        'Psychometric': [[] for _ in range(n_permutations)],\n",
    "        'fMRI': [[] for _ in range(n_permutations)],\n",
    "        'EEG': [[] for _ in range(n_permutations)]\n",
    "    }\n",
    "    \n",
    "    # Store true labels for permutation tests (same for all modalities)\n",
    "    permutation_true_labels = []\n",
    "    \n",
    "    WIN_STEP = 5      \n",
    "    TR = 0.8     \n",
    "    K_STATES_LIST_fMRI = list(range(5, 11))\n",
    "    K_STATES_LIST_EEG = list(range(6, 12))\n",
    "    \n",
    "    for fold, (train_subjects, test_subjects) in enumerate(fold_splits):\n",
    "        print(f\"Processing permutations for fold {fold + 1}/{len(fold_splits)}\")\n",
    "        \n",
    "        # Apply splits to each modality\n",
    "        eeg_train_idx = get_indices_for_subjects(eeg_data['sub_ids'], train_subjects)\n",
    "        eeg_test_idx = get_indices_for_subjects(eeg_data['sub_ids'], test_subjects)\n",
    "        \n",
    "        fmri_train_idx = get_indices_for_subjects(fmri_data['sub_ids'], train_subjects)\n",
    "        fmri_test_idx = get_indices_for_subjects(fmri_data['sub_ids'], test_subjects)\n",
    "        \n",
    "        smri_train_idx = get_indices_for_subjects(smri_data['sub_ids'], train_subjects)\n",
    "        smri_test_idx = get_indices_for_subjects(smri_data['sub_ids'], test_subjects)\n",
    "        \n",
    "        psychometric_train_idx = get_indices_for_subjects(psychometric_data['sub_ids'], train_subjects)\n",
    "        psychometric_test_idx = get_indices_for_subjects(psychometric_data['sub_ids'], test_subjects)\n",
    "        \n",
    "        # Extract training and testing data for each modality\n",
    "        X_train_eeg = eeg_data['X'][eeg_train_idx]\n",
    "        y_train_eeg = eeg_data['y'][eeg_train_idx]\n",
    "        X_test_eeg = eeg_data['X'][eeg_test_idx]\n",
    "        y_test_eeg = eeg_data['y'][eeg_test_idx]\n",
    "        \n",
    "        X_train_fmri = fmri_data['X'][fmri_train_idx]\n",
    "        y_train_fmri = fmri_data['y'][fmri_train_idx]\n",
    "        X_test_fmri = fmri_data['X'][fmri_test_idx]\n",
    "        y_test_fmri = fmri_data['y'][fmri_test_idx]\n",
    "        \n",
    "        X_train_smri = smri_data['X'][smri_train_idx]\n",
    "        y_train_smri = smri_data['y'][smri_train_idx]\n",
    "        X_test_smri = smri_data['X'][smri_test_idx]\n",
    "        y_test_smri = smri_data['y'][smri_test_idx]\n",
    "        \n",
    "        X_train_psychometric = psychometric_data['X'][psychometric_train_idx]\n",
    "        y_train_psychometric = psychometric_data['y'][psychometric_train_idx]\n",
    "        X_test_psychometric = psychometric_data['X'][psychometric_test_idx]\n",
    "        y_test_psychometric = psychometric_data['y'][psychometric_test_idx]\n",
    "\n",
    "        # Store true labels for permutation (same across all modalities)\n",
    "        permutation_true_labels.extend(y_test_smri)\n",
    "\n",
    "        # ====== sMRI PERMUTATION TESTING ======\n",
    "        print(f\"  Running sMRI permutations...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_smri_scaled = scaler.fit_transform(X_train_smri)\n",
    "        X_test_smri_scaled = scaler.transform(X_test_smri)\n",
    "\n",
    "        counts = np.bincount(y_train_smri)\n",
    "        scale_pos_weight = counts[0] / counts[1] if counts.size > 1 and counts[1] > 0 else 1.0\n",
    "\n",
    "        for perm in range(n_permutations):\n",
    "            y_train_perm = np.random.permutation(y_train_smri)\n",
    "            model_perm = xgb.XGBClassifier(\n",
    "                n_estimators=100, max_depth=6, learning_rate=0.05, eval_metric=\"logloss\",\n",
    "                random_state=SEED + perm, scale_pos_weight=scale_pos_weight, tree_method=\"hist\",\n",
    "                device=\"cuda\", verbosity=0\n",
    "            )\n",
    "            model_perm.fit(X_train_smri_scaled, y_train_perm)\n",
    "            y_pred_perm_prob = model_perm.predict_proba(X_test_smri_scaled)[:, 1]\n",
    "            y_pred_perm = (y_pred_perm_prob >= 0.5).astype(int)\n",
    "            permutation_predictions['sMRI'][perm].extend(y_pred_perm)\n",
    "\n",
    "        # ====== PSYCHOMETRIC PERMUTATION TESTING ======\n",
    "        print(f\"  Running Psychometric permutations...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_train_psychometric_scaled = scaler.fit_transform(X_train_psychometric)\n",
    "        X_test_psychometric_scaled = scaler.transform(X_test_psychometric)\n",
    "\n",
    "        counts = np.bincount(y_train_psychometric)\n",
    "        scale_pos_weight = counts[0] / counts[1] if counts.size > 1 and counts[1] > 0 else 1.0\n",
    "        \n",
    "        for perm in range(n_permutations):\n",
    "            y_train_perm = np.random.permutation(y_train_psychometric)\n",
    "            model_perm = xgb.XGBClassifier(\n",
    "                n_estimators=100, max_depth=6, learning_rate=0.05, eval_metric=\"logloss\",\n",
    "                random_state=SEED + perm, scale_pos_weight=scale_pos_weight, tree_method=\"hist\",\n",
    "                device=\"cuda\", verbosity=0\n",
    "            )\n",
    "            model_perm.fit(X_train_psychometric_scaled, y_train_perm)\n",
    "            y_pred_perm_prob = model_perm.predict_proba(X_test_psychometric_scaled)[:, 1]\n",
    "            y_pred_perm = (y_pred_perm_prob >= 0.5).astype(int)\n",
    "            permutation_predictions['Psychometric'][perm].extend(y_pred_perm)\n",
    "\n",
    "        # ====== fMRI PERMUTATION TESTING ======\n",
    "        print(f\"  Running fMRI permutations...\")\n",
    "        from scipy.stats import kruskal, mannwhitneyu, shapiro, levene, f_oneway, ttest_ind\n",
    "        from sklearn.pipeline import make_pipeline\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "        STEP_SEC = WIN_STEP * TR\n",
    "        NORMALITY_ALPHA = 0.05\n",
    "        VARIANCE_ALPHA = 0.05\n",
    "        MIN_SAMPLE_SIZE = 3\n",
    "        P_VALUE_SMOOTHING = 1e-10\n",
    "        WEIGHT_POWER = 2.0\n",
    "\n",
    "        def test_normality_and_variance(groups, state_id, fold_id):\n",
    "            test_details = {\n",
    "                'state': state_id, 'fold': fold_id, 'n_groups': len(groups),\n",
    "                'group_sizes': [len(g) for g in groups], 'use_parametric': False,\n",
    "                'reason': ''\n",
    "            }\n",
    "            if any(len(g) < MIN_SAMPLE_SIZE for g in groups):\n",
    "                test_details['reason'] = f'Sample size too small (min {MIN_SAMPLE_SIZE} required)'\n",
    "                return False, test_details\n",
    "            normality_pvals = [shapiro(g)[1] if len(g) >= 3 else 0.0 for g in groups]\n",
    "            if not all(p > NORMALITY_ALPHA for p in normality_pvals):\n",
    "                test_details['reason'] = 'One or more groups not normally distributed'\n",
    "                return False, test_details\n",
    "            try:\n",
    "                if levene(*groups)[1] <= VARIANCE_ALPHA:\n",
    "                    test_details['reason'] = 'Unequal variances detected'\n",
    "                    return False, test_details\n",
    "            except:\n",
    "                test_details['reason'] = 'Could not test variance homogeneity'\n",
    "                return False, test_details\n",
    "            test_details['reason'] = 'All parametric assumptions satisfied'\n",
    "            test_details['use_parametric'] = True\n",
    "            return True, test_details\n",
    "\n",
    "        def choose_statistical_test_adaptive(groups, state_id, fold_id):\n",
    "            if len(groups) < 2 or any(g.size == 0 for g in groups) or np.std(np.concatenate(groups)) <= 1e-10:\n",
    "                return 'None', 1.0, 0.0\n",
    "            use_parametric, _ = test_normality_and_variance(groups, state_id, fold_id)\n",
    "            try:\n",
    "                if use_parametric:\n",
    "                    test_func = ttest_ind if len(groups) == 2 else f_oneway\n",
    "                    stat, p_val = test_func(*groups)\n",
    "                    return ('t-test' if len(groups) == 2 else 'ANOVA'), p_val, stat\n",
    "                else:\n",
    "                    test_func = mannwhitneyu if len(groups) == 2 else kruskal\n",
    "                    stat, p_val = test_func(*groups)\n",
    "                    return ('Mann-Whitney' if len(groups) == 2 else 'Kruskal-Wallis'), p_val, stat\n",
    "            except Exception:\n",
    "                return 'None', 1.0, 0.0\n",
    "\n",
    "        def compute_pvalue_weights(p_values, smoothing=P_VALUE_SMOOTHING, power=WEIGHT_POWER):\n",
    "            smoothed_p_values = np.array(p_values) + smoothing\n",
    "            inverse_p = (1.0 / smoothed_p_values) ** power\n",
    "            return inverse_p / np.sum(inverse_p)\n",
    "\n",
    "        def weighted_prediction(probabilities, weights):\n",
    "            weighted_prob = np.average(probabilities, axis=1, weights=weights)\n",
    "            return (weighted_prob > 0.5).astype(int), weighted_prob\n",
    "\n",
    "        def compute_subject_dwell_times(X_data, y_data, sub_ids_data, target_subjects, kmeans_model, k_states):\n",
    "            subject_features, subject_labels, processed_subjects = [], [], []\n",
    "            for subject in target_subjects:\n",
    "                subject_mask = sub_ids_data == subject\n",
    "                if not np.any(subject_mask): continue\n",
    "                subject_fmri = X_data[subject_mask]\n",
    "                subject_preds = kmeans_model.predict(subject_fmri)\n",
    "                subject_dwell_times = np.bincount(subject_preds, minlength=k_states) * STEP_SEC\n",
    "                subject_features.append(subject_dwell_times)\n",
    "                subject_labels.append(y_data[subject_mask][0])\n",
    "                processed_subjects.append(subject)\n",
    "            return np.array(subject_features), np.array(subject_labels), processed_subjects\n",
    "\n",
    "        # Pre-compute K-means models and subject features for efficiency\n",
    "        kmeans_models = {}\n",
    "        X_train_fmri_subjects_all = {}\n",
    "        X_test_fmri_subjects_all = {}\n",
    "        \n",
    "        for K_STATES in K_STATES_LIST_fMRI:\n",
    "            kmeans = KMeans(n_clusters=K_STATES, random_state=SEED, n_init=\"auto\").fit(X_train_fmri)\n",
    "            kmeans_models[K_STATES] = kmeans\n",
    "            \n",
    "            X_train_fmri_subjects, y_train_fmri_subjects, _ = compute_subject_dwell_times(\n",
    "                X_train_fmri, y_train_fmri, fmri_data['sub_ids'][fmri_train_idx], train_subjects, kmeans, K_STATES)\n",
    "            X_test_fmri_subjects, y_test_fmri_subjects, _ = compute_subject_dwell_times(\n",
    "                X_test_fmri, y_test_fmri, fmri_data['sub_ids'][fmri_test_idx], test_subjects, kmeans, K_STATES)\n",
    "            \n",
    "            X_train_fmri_subjects_all[K_STATES] = X_train_fmri_subjects\n",
    "            X_test_fmri_subjects_all[K_STATES] = X_test_fmri_subjects\n",
    "\n",
    "        for perm in range(n_permutations):\n",
    "            y_train_perm = np.random.permutation(y_train_fmri_subjects)\n",
    "            \n",
    "            perm_results_per_k = []\n",
    "            perm_fold_p_values = []\n",
    "\n",
    "            for K_STATES in K_STATES_LIST_fMRI:\n",
    "                X_train_subjects = X_train_fmri_subjects_all[K_STATES]\n",
    "                X_test_subjects = X_test_fmri_subjects_all[K_STATES]\n",
    "                \n",
    "                # Feature selection with permuted labels\n",
    "                pvals = []\n",
    "                for state in range(K_STATES):\n",
    "                    groups = [X_train_subjects[y_train_perm == label, state] for label in np.unique(y_train_perm)]\n",
    "                    _, p_value, _ = choose_statistical_test_adaptive(groups, state, fold)\n",
    "                    pvals.append(p_value)\n",
    "                \n",
    "                best_state_idx = np.argmin(pvals)\n",
    "                perm_fold_p_values.append(pvals[best_state_idx])\n",
    "                \n",
    "                clf_perm = make_pipeline(MinMaxScaler(), LogisticRegression(penalty=None, class_weight=\"balanced\", random_state=SEED + perm))\n",
    "                clf_perm.fit(X_train_subjects[:, [best_state_idx]], y_train_perm)\n",
    "                \n",
    "                perm_prob = clf_perm.predict_proba(X_test_subjects[:, [best_state_idx]])[:, 1]\n",
    "                perm_results_per_k.append({'probabilities': perm_prob})\n",
    "\n",
    "            perm_ensemble_weights = compute_pvalue_weights(perm_fold_p_values)\n",
    "            perm_all_probabilities = np.column_stack([res['probabilities'] for res in perm_results_per_k])\n",
    "            perm_pred, _ = weighted_prediction(perm_all_probabilities, perm_ensemble_weights)\n",
    "            \n",
    "            permutation_predictions['fMRI'][perm].extend(perm_pred)\n",
    "\n",
    "        # ====== EEG PERMUTATION TESTING ======\n",
    "        print(f\"  Running EEG permutations...\")\n",
    "        EEG_WINDOW_SIZE_SEC = 4.0\n",
    "        EEG_OVERLAP_PERCENT = 0.75\n",
    "        STEP_SEC = EEG_WINDOW_SIZE_SEC * (1 - EEG_OVERLAP_PERCENT)\n",
    "        \n",
    "        def compute_eeg_subject_features(X_data, y_data, sub_ids_data, target_subjects, kmeans_model, k_states):\n",
    "            subject_features, subject_labels, processed_subjects = [], [], []\n",
    "            for subject in target_subjects:\n",
    "                subject_mask = sub_ids_data == subject\n",
    "                if not np.any(subject_mask): continue\n",
    "                subject_eeg = X_data[subject_mask]\n",
    "                subject_eeg_flat = subject_eeg.reshape(subject_eeg.shape[0], -1)\n",
    "                subject_preds = kmeans_model.predict(subject_eeg_flat)\n",
    "                subject_dwell_times = np.bincount(subject_preds, minlength=k_states) * STEP_SEC\n",
    "                subject_features.append(subject_dwell_times)\n",
    "                subject_labels.append(y_data[subject_mask][0])\n",
    "                processed_subjects.append(subject)\n",
    "            return np.array(subject_features), np.array(subject_labels), processed_subjects\n",
    "\n",
    "        # Pre-process EEG data\n",
    "        X_train_eeg = X_train_eeg[:, np.tril_indices(X_train_eeg.shape[1], k=-1)[0], np.tril_indices(X_train_eeg.shape[1], k=-1)[1], :]\n",
    "        X_test_eeg = X_test_eeg[:, np.tril_indices(X_test_eeg.shape[1], k=-1)[0], np.tril_indices(X_test_eeg.shape[1], k=-1)[1], :]\n",
    "        \n",
    "        # Pre-compute K-means models and subject features for efficiency\n",
    "        kmeans_eeg_models = {}\n",
    "        X_train_eeg_subjects_all = {}\n",
    "        X_test_eeg_subjects_all = {}\n",
    "        \n",
    "        for K_STATES in K_STATES_LIST_EEG:\n",
    "            X_train_eeg_flat = X_train_eeg.reshape(X_train_eeg.shape[0], -1)\n",
    "            kmeans_eeg = KMeans(n_clusters=K_STATES, random_state=SEED, n_init=\"auto\").fit(X_train_eeg_flat)\n",
    "            kmeans_eeg_models[K_STATES] = kmeans_eeg\n",
    "            \n",
    "            X_train_eeg_subjects, y_train_eeg_subjects, _ = compute_eeg_subject_features(\n",
    "                X_train_eeg, y_train_eeg, eeg_data['sub_ids'][eeg_train_idx], train_subjects, kmeans_eeg, K_STATES)\n",
    "            X_test_eeg_subjects, y_test_eeg_subjects, _ = compute_eeg_subject_features(\n",
    "                X_test_eeg, y_test_eeg, eeg_data['sub_ids'][eeg_test_idx], test_subjects, kmeans_eeg, K_STATES)\n",
    "            \n",
    "            X_train_eeg_subjects_all[K_STATES] = X_train_eeg_subjects\n",
    "            X_test_eeg_subjects_all[K_STATES] = X_test_eeg_subjects\n",
    "\n",
    "        for perm in range(n_permutations):\n",
    "            y_train_perm = np.random.permutation(y_train_eeg_subjects)\n",
    "            \n",
    "            perm_results_per_k = []\n",
    "            perm_fold_p_values = []\n",
    "\n",
    "            for K_STATES in K_STATES_LIST_EEG:\n",
    "                X_train_subjects = X_train_eeg_subjects_all[K_STATES]\n",
    "                X_test_subjects = X_test_eeg_subjects_all[K_STATES]\n",
    "                \n",
    "                # Feature selection with permuted labels\n",
    "                pvals = []\n",
    "                for state in range(K_STATES):\n",
    "                    groups = [X_train_subjects[y_train_perm == label, state] for label in np.unique(y_train_perm)]\n",
    "                    _, p_value, _ = choose_statistical_test_adaptive(groups, state, fold)\n",
    "                    pvals.append(p_value)\n",
    "                \n",
    "                best_state_idx = np.argmin(pvals)\n",
    "                perm_fold_p_values.append(pvals[best_state_idx])\n",
    "                \n",
    "                clf_perm = make_pipeline(MinMaxScaler(), LogisticRegression(penalty=None, class_weight=\"balanced\", random_state=SEED + perm))\n",
    "                clf_perm.fit(X_train_subjects[:, [best_state_idx]], y_train_perm)\n",
    "                \n",
    "                perm_prob = clf_perm.predict_proba(X_test_subjects[:, [best_state_idx]])[:, 1]\n",
    "                perm_results_per_k.append({'probabilities': perm_prob})\n",
    "\n",
    "            perm_ensemble_weights = compute_pvalue_weights(perm_fold_p_values)\n",
    "            perm_all_probabilities = np.column_stack([res['probabilities'] for res in perm_results_per_k])\n",
    "            perm_pred, _ = weighted_prediction(perm_all_probabilities, perm_ensemble_weights)\n",
    "            \n",
    "            permutation_predictions['EEG'][perm].extend(perm_pred)\n",
    "\n",
    "    # Compute F1 scores for each permutation\n",
    "    permutation_f1_results = {\n",
    "        'sMRI': [], 'Psychometric': [], 'fMRI': [], 'EEG': []\n",
    "    }\n",
    "    \n",
    "    print(\"\\nComputing F1 scores for permutation distributions...\")\n",
    "    for mod in ['sMRI', 'Psychometric', 'fMRI', 'EEG']:\n",
    "        for perm in range(n_permutations):\n",
    "            f1 = f1_score(permutation_true_labels, permutation_predictions[mod][perm], average='macro', zero_division=0)\n",
    "            permutation_f1_results[mod].append(f1)\n",
    "\n",
    "    return {\n",
    "        'output_dir': output_dir,\n",
    "        'permutation_f1_results': permutation_f1_results,\n",
    "        'permutation_true_labels': permutation_true_labels,\n",
    "        'permutation_predictions': permutation_predictions\n",
    "    }\n",
    "\n",
    "def load_observed_results(results_folder):\n",
    "    \"\"\"Load observed F1 scores from existing CSV files.\"\"\"\n",
    "    observed_results = {}\n",
    "    \n",
    "    # Define all classification tasks\n",
    "    tasks = [\n",
    "        (\"N\", \"A+P-\"),\n",
    "        (\"N\", \"A+P+\"), \n",
    "        (\"A+P-\", \"A+P+\"),\n",
    "        (\"N\", \"A+P-\", \"A+P+\")\n",
    "    ]\n",
    "    \n",
    "    for task in tasks:\n",
    "        class_str = \"_vs_\".join(task).replace(\"+\", \"plus\").replace(\"-\", \"minus\")\n",
    "        csv_path = os.path.join(results_folder, f\"results_{class_str}\", \"multimodal_results_aggregated.csv\")\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            # Extract F1 scores for individual modalities\n",
    "            task_results = {}\n",
    "            for modality in ['sMRI', 'Psychometric', 'fMRI', 'EEG']:\n",
    "                modality_row = df[df['combination'] == modality]\n",
    "                if not modality_row.empty:\n",
    "                    task_results[modality] = modality_row['f1_macro_mean'].iloc[0]\n",
    "                else:\n",
    "                    task_results[modality] = None\n",
    "            \n",
    "            observed_results[class_str] = task_results\n",
    "            print(f\"Loaded observed F1 scores for {class_str}\")\n",
    "        else:\n",
    "            print(f\"Warning: Could not find results for {class_str}\")\n",
    "    \n",
    "    return observed_results\n",
    "\n",
    "def run_comprehensive_permutation_analysis():\n",
    "    \"\"\"Run permutation testing for all classification tasks and compare with observed results.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 120)\n",
    "    print(\"COMPREHENSIVE PERMUTATION TESTING ANALYSIS\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    # Load observed results from CSV files\n",
    "    results_folder = \"final_results_v2\"  # Adjust path as needed\n",
    "    observed_results = load_observed_results(results_folder)\n",
    "    \n",
    "    # Classification tasks to test\n",
    "    tasks = [\n",
    "        (\"N\", \"A+P-\"),\n",
    "        (\"N\", \"A+P+\"), \n",
    "        (\"A+P-\", \"A+P+\"),\n",
    "        (\"N\", \"A+P-\", \"A+P+\")  # Uncomment if you want to test 3-way classification\n",
    "    ]\n",
    "    \n",
    "    all_permutation_results = {}\n",
    "    \n",
    "    for task in tasks:\n",
    "        class_str = \"_vs_\".join(task).replace(\"+\", \"plus\").replace(\"-\", \"minus\")\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RUNNING PERMUTATION TESTING FOR: {class_str}\")\n",
    "        print('='*80)\n",
    "        \n",
    "        # Run permutation analysis\n",
    "        perm_results = run_permutation_analysis(seed_val=42, classes=task, n_permutations=1000)\n",
    "        all_permutation_results[class_str] = perm_results\n",
    "    \n",
    "    # ===== STATISTICAL ANALYSIS =====\n",
    "    print(\"\\n\" + \"=\" * 120)\n",
    "    print(\"PERMUTATION TEST RESULTS SUMMARY\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    summary_results = []\n",
    "    \n",
    "    for task_name, perm_data in all_permutation_results.items():\n",
    "        print(f\"\\nðŸ“Š TASK: {task_name.upper()}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for modality in ['sMRI', 'Psychometric', 'fMRI', 'EEG']:\n",
    "            # Get observed F1 score\n",
    "            if task_name in observed_results and modality in observed_results[task_name]:\n",
    "                observed_f1 = observed_results[task_name][modality]\n",
    "            else:\n",
    "                observed_f1 = None\n",
    "                \n",
    "            if observed_f1 is None:\n",
    "                print(f\"  {modality}: No observed data available\")\n",
    "                continue\n",
    "                \n",
    "            # Get permutation distribution\n",
    "            perm_f1_dist = np.array(perm_data['permutation_f1_results'][modality])\n",
    "            \n",
    "            # Calculate p-value (corrected with +1)\n",
    "            num_greater_equal = np.sum(perm_f1_dist >= observed_f1)\n",
    "            p_value = (num_greater_equal + 1) / (len(perm_f1_dist) + 1)\n",
    "            \n",
    "            # Statistical summary\n",
    "            perm_mean = np.mean(perm_f1_dist)\n",
    "            perm_std = np.std(perm_f1_dist)\n",
    "            \n",
    "            print(f\"  {modality:12}: Obs={observed_f1:.4f}, Perm Î¼={perm_mean:.4f}Â±{perm_std:.4f}, p={p_value:.4f} {'***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else ''}\")\n",
    "            \n",
    "            # Store for summary table\n",
    "            summary_results.append({\n",
    "                'Task': task_name,\n",
    "                'Modality': modality,\n",
    "                'Observed_F1': observed_f1,\n",
    "                'Permutation_Mean_F1': perm_mean,\n",
    "                'Permutation_Std_F1': perm_std,\n",
    "                'p_value': p_value,\n",
    "                'Significant': p_value < 0.05,\n",
    "                'Effect_Size': (observed_f1 - perm_mean) / perm_std if perm_std > 0 else 0\n",
    "            })\n",
    "    \n",
    "    # Create comprehensive summary DataFrame\n",
    "    summary_df = pd.DataFrame(summary_results)\n",
    "    \n",
    "    # ===== FINAL SUMMARY TABLE =====\n",
    "    print(\"\\n\" + \"=\" * 140)\n",
    "    print(\"COMPREHENSIVE PERMUTATION TEST RESULTS\")\n",
    "    print(\"=\" * 140)\n",
    "    \n",
    "    # Format for display\n",
    "    display_summary = summary_df.copy()\n",
    "    display_summary['Observed_F1'] = display_summary['Observed_F1'].apply(lambda x: f\"{x:.4f}\")\n",
    "    display_summary['Permutation_Mean_F1'] = display_summary['Permutation_Mean_F1'].apply(lambda x: f\"{x:.4f}\")\n",
    "    display_summary['Permutation_Std_F1'] = display_summary['Permutation_Std_F1'].apply(lambda x: f\"{x:.4f}\")\n",
    "    display_summary['p_value'] = display_summary['p_value'].apply(lambda x: f\"{x:.4f}\")\n",
    "    display_summary['Effect_Size'] = display_summary['Effect_Size'].apply(lambda x: f\"{x:.4f}\")\n",
    "    display_summary['Significance'] = display_summary['Significant'].apply(lambda x: '***' if x else 'ns')\n",
    "    \n",
    "    print(display_summary[['Task', 'Modality', 'Observed_F1', 'Permutation_Mean_F1', 'Permutation_Std_F1', 'p_value', 'Significance', 'Effect_Size']].to_string(index=False))\n",
    "    \n",
    "    # Save results\n",
    "    results_output_dir = \"permutation_test_analysis\"\n",
    "    os.makedirs(results_output_dir, exist_ok=True)\n",
    "    \n",
    "    summary_df.to_csv(os.path.join(results_output_dir, 'permutation_test_comprehensive_results.csv'), index=False)\n",
    "    \n",
    "    # Save permutation distributions\n",
    "    for task_name, perm_data in all_permutation_results.items():\n",
    "        perm_dist_path = os.path.join(results_output_dir, f'permutation_distributions_{task_name}.npz')\n",
    "        np.savez_compressed(perm_dist_path, **perm_data['permutation_f1_results'])\n",
    "    \n",
    "    print(f\"\\n\\nRESULTS SAVED TO: '{results_output_dir}'\")\n",
    "    print(\"- Comprehensive summary: permutation_test_comprehensive_results.csv\")\n",
    "    print(\"- Permutation distributions: permutation_distributions_*.npz\")\n",
    "    \n",
    "    # ===== SIGNIFICANCE SUMMARY =====\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SIGNIFICANCE SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    sig_count = summary_df[summary_df['Significant']].groupby('Modality').size()\n",
    "    total_count = summary_df.groupby('Modality').size()\n",
    "    \n",
    "    for modality in ['sMRI', 'Psychometric', 'fMRI', 'EEG']:\n",
    "        sig = sig_count.get(modality, 0)\n",
    "        total = total_count.get(modality, 0)\n",
    "        print(f\"{modality:12}: {sig}/{total} tasks significant ({sig/total*100:.1f}%)\")\n",
    "    \n",
    "    return summary_df, all_permutation_results\n",
    "\n",
    "# ===== MAIN EXECUTION =====\n",
    "if __name__ == \"__main__\":\n",
    "    summary_results, permutation_data = run_comprehensive_permutation_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b807a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
